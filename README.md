# éçº¿æ€§è¾å°„æ‰©æ•£é—®é¢˜çš„ç«¯åˆ°ç«¯ç¥ç»ç®—å­ä»£ç†æ¨¡å‹çš„æ„å»º

## ç ”ç©¶ç›®æ ‡ï¼š

é‰´äºè®¸å¤šå¤æ‚å®é™…åº”ç”¨åœºæ™¯å¯¹è®¡ç®—æ•ˆç‡çš„è¿«åˆ‡éœ€æ±‚ï¼Œéœ€è¦åœ¨æ¨¡å‹æ³›åŒ–èƒ½åŠ›å±‚é¢å®ç°çªç ´ã€‚å› æ­¤ï¼Œæœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºç¥ç»ç®—å­ï¼Œä»¥ç›´æ¥å­¦ä¹ ä»ææ–™å‡½æ•°å’Œè¾¹å€¼æ¡ä»¶åˆ°è§£åœºçš„ç«¯åˆ°ç«¯æ˜ å°„ã€‚åŸºäºæ­¤ç›®æ ‡ï¼Œæœ¬é¡¹ç›®å°†æ¢ç´¢è¾å°„æ‰©æ•£æ–¹ç¨‹é€šç”¨æ±‚è§£å™¨çš„æ„å»ºã€‚ä¸ºæ­¤ï¼Œæœ¬é¡¹ç›®èåˆå‚…é‡Œå¶ç¥ç»ç®—å­ï¼ˆFourier Neural Operatorï¼ŒFNOï¼‰ä¸æ·±åº¦ç®—å­ç½‘ç»œï¼ˆDeep Operator Networkï¼ŒDONï¼‰çš„ä¼˜åŠ¿ï¼Œæå‡ºä¸¤ç§æ–°çš„ç«¯åˆ°ç«¯ç¥ç»ç®—å­ä»£ç†æ¨¡å‹Fourier-DONï¼Œç”¨äºå­¦ä¹ ææ–™åˆ†å¸ƒå±æ€§å’Œè¾¹å€¼æ¡ä»¶åˆ°ç‰¹å®šæ—¶åˆ»æ–¹ç¨‹è§£çš„æ˜ å°„å…³ç³»ï¼Œå®ç°å¯¹è¾å°„èƒ½é‡å¯†åº¦å’Œææ–™æ¸©åº¦çš„é¢„æµ‹ï¼Œå¹¶æµ‹è¯•è¯„ä¼°æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ³›åŒ–æ€§ã€‚

## é—®é¢˜æè¿°ï¼š

éçº¿æ€§è¾å°„æ‰©æ•£é—®é¢˜æ˜¯ä¸€ç±»å…¸å‹çš„å¤šå°ºåº¦å¼ºè€¦åˆè¾“è¿æ–¹ç¨‹ï¼Œå…¶æ ¸å¿ƒåœ¨äºæè¿°è¾å°„èƒ½é‡ä¸ç‰©è´¨èƒ½é‡é€šè¿‡å…‰å­è¾“è¿äº§ç”Ÿçš„éçº¿æ€§èƒ½é‡äº¤æ¢è¿‡ç¨‹ã€‚è¯¥è¿‡ç¨‹çš„æ§åˆ¶æ–¹ç¨‹å¯è¡¨è¿°ä¸ºï¼š

### å•æ¸©é—®é¢˜ï¼š

$$
\begin{aligned}
   & \frac{\partial E}{\partial t}-\nabla\cdot(D_L\nabla E) = 0, \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = \beta(x,y,t), \quad(x,y,t)\in\lbrace x=0\rbrace\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = 0, \quad(x,y,t)\in\partial\Omega\setminus\lbrace x=0\rbrace\times[0,1] \\
   & E|_{t=0} = g(x,y,0)
\end{aligned}
$$

å…¶ä¸­ $\Omega = [0,1]\times[0,1]$ ï¼›è¾å°„æ‰©æ•£ç³»æ•° $D_L$ é€‰ç”¨é™æµå½¢å¼ï¼Œå³ $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}$ ã€‚

### åŒæ¸©é—®é¢˜ï¼š

$$
\begin{aligned}
   & \frac{\partial E}{\partial t} - \nabla \cdot (D_L \nabla E) = \sigma_{\alpha}(T^4 - E), \quad(x,y,t)\in\Omega\times[0,1] \\
   & \frac{\partial T}{\partial t} - \nabla \cdot (K_L \nabla T) = \sigma_{\alpha}(E - T^4), \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E + D_L \nabla E \cdot n = \beta(x,y,t), \quad (x,y,t) \in \lbrace x=0 \rbrace \times [0,1] \\
   & 0.5E + D_L \nabla E \cdot n = 0, \quad (x,y,t) \in \partial\Omega \setminus \lbrace x=0 \rbrace \times [0,1] \\
   & K_L \nabla T \cdot n = 0, \quad (x,y,t) \in \partial\Omega \times [0,1] \\
   & E\vert_{t=0} = g(x,y,0) \\
   & T^4\vert_{t=0} = g(x,y,0)
\end{aligned}
$$

å…¶ä¸­ $\Omega = [0,1]\times[0,1]$ ï¼›è¾å°„æ‰©æ•£ç³»æ•° $D_L, K_L$ åŒæ ·é€‰ç”¨é™æµå½¢å¼ï¼Œå³ $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}, K_L = \frac{T^4}{T^{3/2}z+T^{5/2}|\nabla T|}$ ã€‚

å¯¹äºä¸Šè¿°å•æ¸©ã€åŒæ¸©é—®é¢˜ï¼Œææ–™å‡½æ•° $z$ é‡‡ç”¨åŒæ–¹å½¢ï¼Œå³åœ¨ $\Omega$ å†…çš„ä¸¤ä¸ª0.25Ã—0.25çš„æ–¹å½¢åŒºåŸŸä¸­ï¼Œ $z=9$ ï¼›å…¶ä»–æ—¶å€™ $z=1$ ã€‚é»˜è®¤è®¾ç½®è¿™ä¸¤ä¸ªæ–¹å½¢åŒºåŸŸå·¦ä¸‹è§’çš„åæ ‡åˆ†åˆ«ä¸º $(\frac{3}{16},\frac{9}{16}),(\frac{9}{16},\frac{3}{16})$ ã€‚

åˆå€¼æ¡ä»¶é‡‡ç”¨å¸¸æ•°åˆå€¼ï¼Œå³ $g(x,y,t) = 0.01$ ï¼›è¾¹å€¼æ¡ä»¶é‡‡ç”¨çº¿æ€§è¾¹å€¼ï¼Œå³å½“ $t<t_1$ æ—¶ï¼Œ $\beta(x,y,t)=\frac{\beta_{\text{max}}}{t_1} t$ ï¼›å½“ $t\leq t_1$ æ—¶ï¼Œ $\beta(x,y,t)=\beta_{\text{max}}$ ã€‚é»˜è®¤è®¾ç½® $t_1=0.5,\beta_{\text{max}}=10$ ã€‚

### ç®—å­å­¦ä¹ ä»»åŠ¡ï¼š

æœ¬é¡¹ç›®éœ€è¦ç ”ç©¶çš„å…­ä¸ªç®—å­å­¦ä¹ ä»»åŠ¡å¦‚ä¸‹ï¼š

|                    | ä»»åŠ¡                           |
|--------------------|--------------------------------|
| å•æ¸©               | $z \rightarrow E$              |
|                    | $z \times t_1 \rightarrow E$   |
|                    | $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ |
| åŒæ¸©               | $z \rightarrow E, T$           |
|                    | $z \times t_1 \rightarrow E, T$ |
|                    | $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ |

## ç®—æ³•è®¾è®¡ï¼š

æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œæ›¿ä»£æ¨¡å‹ï¼Œç”¨äºå¤„ç†å¤šè¾“å…¥ç®—å­ $ğ’³_1\times ğ’³_2\rightarrow ğ’´$ ï¼Œå…¶ä¸­ $ğ’³_1$ è¡¨ç¤ºææ–™å‡½æ•° $z$ çš„å‡½æ•°ç©ºé—´ï¼Œ $ğ’³_2$ è¡¨ç¤ºè¾¹å€¼æ¡ä»¶ $\beta$ çš„å‡½æ•°ç©ºé—´ï¼Œğ’´è¡¨ç¤ºç›®æ ‡å‡½æ•°ç©ºé—´ã€‚ä¸ºæ­¤ï¼Œå¯¹åŸå§‹DONè¿›è¡Œä¿®æ”¹ï¼Œä½¿å…¶åˆ†æ”¯ç½‘ç»œå’Œä¸»å¹²ç½‘ç»œèƒ½åˆ†åˆ«æ¥å—ç¦»æ•£ææ–™å‡½æ•°ï¼ˆè¡¨ç¤ºä¸º $Z$ ï¼‰å’Œç¦»æ•£è¾¹å€¼å‡½æ•°ï¼ˆè¡¨ç¤ºä¸º $\xi$ ï¼‰ï¼Œå¼€å‘äº†ä¸¤ç§å˜ä½“ï¼šç¬¬ä¸€ç±»Fourier-DONå’Œç¬¬äºŒç±»Fourier-DONã€‚

é’ˆå¯¹è¾¹å€¼æ¡ä»¶å›ºå®šçš„è¾å°„æ‰©æ•£é—®é¢˜ï¼Œæˆ‘ä»¬ç›´æ¥é‡‡ç”¨FNOæ¡†æ¶æ±‚è§£ï¼Œåœ¨Fourierå±‚ä¹‹åå¢åŠ äº†ä¸€ä¸ªé¢å¤–çš„çº¿æ€§å±‚ï¼Œç›´æ¥å°†è¾“å‡ºæ˜ å°„åˆ°è§£ç©ºé—´ã€‚è€Œå¯¹äºéå›ºå®šè¾¹å€¼æ¡ä»¶çš„è¾å°„æ‰©æ•£é—®é¢˜ï¼Œæœ¬é¡¹ç›®åˆ›æ–°æ€§åœ°è®¾è®¡äº†ä¸¤ç§ç«¯åˆ°ç«¯ç¥ç»ç®—å­ä»£ç†æ¨¡å‹Fourier-DONã€‚ä¸‹é¢å°†ä»¥å•æ¸©é—®é¢˜ä¸ºä¾‹å±•å¼€è¯´æ˜ã€‚å¯¹äºåŒæ¸©é—®é¢˜ï¼Œå¯æ„å»ºä¸¤ä¸ªå¹¶è¡Œç½‘ç»œåˆ†æ”¯åˆ†åˆ«å­¦ä¹ è¾å°„èƒ½é‡å¯†åº¦ğ„ä¸ææ–™æ¸©åº¦ğ“ã€‚

### Type-1 Fourier-DONç®—æ³•è®¾è®¡ï¼š

Type-1 Fourier-DONçš„æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå…¶ä¸­åˆ†æ”¯ç½‘ç»œè¡¨ç¤ºä¸º $B_\theta$ ï¼Œä¸»å¹²ç½‘ç»œè¡¨ç¤ºä¸º $T_\theta$ ã€‚è¯¥æ–¹æ³•ç»“åˆäº†FNOå’ŒDONçš„ä¼˜åŠ¿ï¼Œåˆ†æ”¯ç½‘ç»œé€šè¿‡Fourierå±‚å­¦ä¹ åŸºå‡½æ•°ï¼Œå¹¶åœ¨ä¸»å¹²ç½‘ç»œä¸­ä»¥å…¨è¿æ¥ç½‘ç»œå­¦ä¹ å¯¹åº”ç³»æ•°ï¼Œä»¥åŸºå‡½æ•°ä¸ç³»æ•°çš„çº¿æ€§ç»„åˆç”Ÿæˆé¢„æµ‹è§£ã€‚

<img src="./result/figs/fno-deeponet-type1.jpg" alt="type1-model" width="300" />

å°†ææ–™å‡½æ•° $z$ ç¼©æ”¾åˆ°èŒƒå›´(0,1)ï¼Œå¹¶ä¸ç›¸åº”çš„äºŒç»´ç½‘æ ¼åæ ‡ $x,yâˆˆâ„^{m\times m}$ æ‹¼æ¥ï¼Œå½¢æˆ $ğ™=[z,x,y]âˆˆâ„^{m\times m\times 3}$ ï¼Œä½œä¸ºåˆ†æ”¯ç½‘ç»œçš„è¾“å…¥å±‚ï¼Œå…¶ä¸­ $m$ è¡¨ç¤ºç©ºé—´ç»´åº¦ã€‚å†å°†è¾¹å€¼å‡½æ•°çš„å‚æ•° $t_1âˆˆâ„$ å’Œ $\beta_{\text{max}}âˆˆâ„$ ä¹Ÿç¼©æ”¾åˆ°(0,1)ï¼Œå¹¶æ‹¼æ¥æˆ $[t_1,\beta_{\text{max}}]âˆˆâ„^2$ ï¼Œä½œä¸ºä¸»å¹²ç½‘ç»œçš„è¾“å…¥å±‚ã€‚

åˆ†æ”¯ç½‘ç»œé¦–å…ˆç”±ä¸€ä¸ªçº¿æ€§å±‚ç»„æˆï¼Œè¯¥å±‚å°† $â„^{m\times m\times 3}$ æ˜ å°„åˆ° $â„^{m\times m\times 32}$ ï¼›éšåæ˜¯å››ä¸ªFourierå±‚ï¼Œæ¯å±‚åŒ…å«12ä¸ªæ¨¡å¼å’Œ32ä¸ªé€šé“ï¼Œå±‚å†…çš„é€ç‚¹å˜æ¢å—å®ç°ä¸ºä¸€ä¸ªä¸¤å±‚FCNï¼Œæ¯å±‚æœ‰32ä¸ªéšè—å•å…ƒã€‚ä¸»å¹²ç½‘ç»œè®¾ç½®ä¸ºä¸€ä¸ªå››å±‚FCNï¼Œæ¯å±‚æœ‰32ä¸ªéšè—å•å…ƒã€‚é™¤æœ€åä¸€å±‚å¤–ï¼Œä¸¤ä¸ªç½‘ç»œæ‰€æœ‰å±‚çš„æ¿€æ´»å‡½æ•°å‡é€‰ä¸ºGeLUå‡½æ•°ã€‚

å¯¹äºå…·æœ‰å›ºå®šè¾¹å€¼æ¡ä»¶çš„ä»»åŠ¡ï¼ŒFNOç½‘ç»œå¯ä»¥è§†ä¸ºçœç•¥äº†ä¸»å¹²ç½‘ç»œã€åˆ†æ”¯ç½‘ç»œåœ¨Fourierå±‚ä¹‹åå¢åŠ äº†ä¸€ä¸ªé¢å¤–çº¿æ€§å±‚å°†è¾“å‡ºæ˜ å°„åˆ°è§£ç©ºé—´çš„Type-1 Fourier-DONã€‚

åˆ†æ”¯å’Œä¸»å¹²ç½‘ç»œçš„è¾“å‡ºä¸ºï¼š

$$
\begin{aligned}
   & ğ• = B_\theta (ğ™)âˆˆâ„^{m\times m\times c}, \\
   & ğ›š = T_\theta (\xi)âˆˆâ„^c,
\end{aligned}
$$

å…¶ä¸­ $c$ æ˜¯é€šé“æ•°ï¼Œğ•å¯ä»¥çœ‹æˆä¸€åˆ—åŸºå‡½æ•° $[ğ•_1,...,ğ•_c]$ ï¼Œğ›šå¯ä»¥çœ‹æˆä¸€åˆ—ç³»æ•° $[ğ›š_1,...,ğ›š_c]$ ã€‚å¯¹ä¸Šè¿°ä¸¤ä¸ªè¾“å‡ºè¿›è¡Œçº¿æ€§ç»„åˆå¾—åˆ°æœ€ç»ˆè¾“å‡ºï¼š

$$
\begin{equation}
   ğ„Ìƒ = \sum_i ğ›š_i ğ•_i.
\end{equation}
$$

å…¶ä¸­ğ„Ìƒè¡¨ç¤ºç”±ç¥ç»ç½‘ç»œé¢„æµ‹å¾—åˆ°çš„ç›®æ ‡å‡½æ•°ï¼Œé€šè¿‡æœ€å°åŒ–ç½‘ç»œè¾“å‡ºä¸æ•°å€¼å‚è€ƒè§£çš„ç›¸å¯¹ $L_2$ è¯¯å·®æŸå¤±å‡½æ•° $L=\frac{â€–ğ„-ğ„Ìƒâ€–â‚‚}{â€–ğ„â€–â‚‚}$ ï¼Œå°½å¯èƒ½é€¼è¿‘çœŸå®ç›®æ ‡å‡½æ•° $ğ„âˆˆâ„^{m\times m}$ ã€‚

ä»¥ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ ä¸ºä¾‹ï¼ŒType-1 Fourier-DONçš„å…·ä½“è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src="./result/figs/fno-deeponet-type1-train.jpg" alt="type1-train" width="700" />

### Type-2 Fourier-DONï¼š

Type-2 Fourier-DONçš„æ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œè§£ç å™¨è¡¨ç¤ºä¸º $\Phi_\theta$ ã€‚è¯¥ç®—å­ä¹Ÿç»“åˆäº†FNOå’ŒDONçš„ä¼˜åŠ¿ï¼Œé‡‡ç”¨ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œé€šè¿‡å…¨è¿æ¥å±‚åˆ†åˆ«å°†ææ–™å‡½æ•°å’Œè¾¹å€¼æ¡ä»¶å‚æ•°æŠ•å½±åˆ°ç‰¹å¾ç©ºé—´ï¼Œå°†ä¸»å¹²ç½‘ç»œä¸åˆ†æ”¯ç½‘ç»œçš„è¾“å‡ºè¿›è¡Œé€ç‚¹å†…ç§¯åè¾“å…¥FNOè§£ç å™¨ç”Ÿæˆæœ€ç»ˆè§£ã€‚

<img src="./result/figs/fno-deeponet-type2.jpg" alt="type2-model" width="400" />

åˆ†æ”¯ç½‘ç»œå’Œä¸»å¹²ç½‘ç»œçš„è¾“å…¥å¤„ç†ä¸Type-1æ¨¡å‹çš„å¤„ç†ç›¸åŒã€‚

åˆ†æ”¯ç½‘ç»œå’Œä¸»å¹²ç½‘ç»œå‡é€šè¿‡ä¸€ä¸ªçº¿æ€§å±‚å®ç°ï¼Œè¯¥å±‚å°† $â„^{m\times m\times 3}$ æ˜ å°„åˆ° $â„^{m\times m\times 32}$ ï¼Œç„¶åè¿›è¡Œé€å…ƒç´ ä¹˜æ³•ã€‚å°†è¾“å‡º $ğ•âˆˆâ„^{m\times m\times 32}$ é€å…¥ä¸€ä¸ªFNOè§£ç å™¨ï¼Œè¯¥è§£ç å™¨åŒ…å«å››ä¸ªFourierå±‚ï¼ˆæ¯ä¸ªå±‚ä¸ç¬¬ä¸€ç±»ä¸­çš„ç›¸åŒï¼‰ä»¥åŠä¸€ä¸ªåŒ…å«32ä¸ªéšè—å•å…ƒçš„ä¸¤å±‚FCNã€‚

ç¦»æ•£åŒ–çš„ç›®æ ‡å‡½æ•° $ğ„âˆˆâ„^{m\times m}$ è¿‘ä¼¼ä¸ºï¼š

$$
\begin{aligned}
   & ğ = B_\theta (ğ™)âˆˆâ„^{m\times m\times c}, \\
   & ğ— = T_\theta (\xi)âˆˆâ„^c, \\
   & ğ•_{i,j} = ğ_{i,j}âŠ™ğ—, \\
   & ğ„Ìƒ = \Phi_\theta (ğ•^{(0)})
\end{aligned}
$$

å…¶ä¸­ $i,jâˆˆ[0,m-1]$ è¡¨ç¤ºğå’Œğ•çš„ç©ºé—´ç´¢å¼•ï¼ŒâŠ™è¡¨ç¤ºé€å…ƒç´ ä¹˜ç§¯ã€‚æŸå¤±å‡½æ•°åŒæ ·è®¾ç½®ä¸ºç›¸å¯¹ $L_2$ è¯¯å·®å¼ã€‚

ä»¥ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ ä¸ºä¾‹ï¼ŒType-2 Fourier-DONçš„å…·ä½“è®­ç»ƒè¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

<img src="./result/figs/fno-deeponet-type2-train.jpg" alt="type2-train" width="700" />

## ä»£ç ä»‹ç»ï¼š

### é¡¹ç›®ç»“æ„ï¼š
   
```
operator_learning-nonlinear_diffusion/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ nd/
â”‚   â””â”€â”€ nd_seq/
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ exps/
â”‚   â”œâ”€â”€ seq_exps/
â”‚   â”œâ”€â”€ figs/
â”‚   â””â”€â”€ result_process.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ nets.py
â”‚   â”œâ”€â”€ utils.sh
â”‚   â”œâ”€â”€ default_exps.sh
â”‚   â”œâ”€â”€ nlayer_exps.sh
â”‚   â”œâ”€â”€ ntrain_exps.sh
â”‚   â”œâ”€â”€ modes_exps.sh
â”‚   â”œâ”€â”€ width_exps.sh
â”‚   â”œâ”€â”€ superres_exps.sh
â”‚   â””â”€â”€ seq_exps.sh
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### å‚æ•°è®¾ç½®ï¼š

|å‚æ•°      |è¯´æ˜      |é»˜è®¤å€¼      |
|:--------:|:--------:|:--------:|
|data-root    |æ•°æ®é›†æ ¹ç›®å½•è·¯å¾„ï¼ˆ`../dataset/nd/`æˆ–`../dataset/nd_seq/`ï¼‰        |`../dataset/nd/`       |
|task         |ä»»åŠ¡åç§°ï¼ˆä¾‹ï¼š`heat-1T-zsquares`, `heat-2T-zsquares-t1-bmax`ï¼‰   |`heat-1T-zsquares`     |
|num-train   |è®­ç»ƒæ ·æœ¬æ•°é‡                      |600          |
|num-test    |æµ‹è¯•æ ·æœ¬æ•°é‡                      |100          |
|batch-size  |è®­ç»ƒæ‰¹æ¬¡å¤§å°                      |4            |
|seed        |éšæœºç§å­ï¼ˆç”¨äºç»“æœå¤ç°ï¼‰            |0           |
|lr          |åˆå§‹å­¦ä¹ ç‡                        |1e-3         |
|epochs      |è®­ç»ƒå‘¨æœŸæ•°                        |100          |
|modes       | $x$ å’Œ $y$ æ–¹å‘çš„Fourieræ¨¡æ•°               |12           |
|width       |ç½‘ç»œé€šé“æ•°                        |32           |
|grid-size   |ç©ºé—´ç½‘æ ¼åˆ†è¾¨ç‡                     |129          |
|output-dir  |è®­ç»ƒç»“æœä¿å­˜ç›®å½•                   |`../result/`   |
|num-branch  |åˆ†æ”¯å±‚æ•°ï¼ˆFourierå±‚ï¼‰              |4            |
|num-trunk   |ä¸»å¹²å±‚æ•°ï¼ˆType-1 Fourier-DONçš„çº¿æ€§å±‚ï¼‰         |2            |
|device      |GPUè®¾å¤‡ID                         |0            |
|ratio       |ç©ºé—´é‡‡æ ·ç‡ï¼ˆ1ã€2æˆ–4ï¼‰              |1            |
|arch        |æ¨¡å‹æ¶æ„ï¼ˆ`fno`, `fdon1`æˆ–`fdon2`ï¼‰|`fno`          |

### è¿è¡Œç¯å¢ƒï¼š

**ç¡¬ä»¶**ï¼š

- GPU: NVIDIA GPU

**è½¯ä»¶ç¯å¢ƒ**ï¼š

- Python ç‰ˆæœ¬: Python 3.11.3

- Shell ç¯å¢ƒ: Bash

**Python ä¾èµ–é¡¹**ï¼š

- h5py==3.10.0

- torch==2.3.1

- numpy==2.2.5

- scipy==1.15.3

- matplotlib==3.10.3

- pandas==2.2.3

- SciencePlots==2.1.1

### è®¾ç½®ï¼š

1. **ä¸‹è½½æ•°æ®é›†ä»¥åŠç»“æœ**ï¼š
   - ä»[https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde](https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde)è®¿é—®æ•°æ®é›†å’Œç»“æœ
   - è§£å‹`dataset.zip`å’Œ`result.zip`æ–‡ä»¶
   - æ ¹æ®ä¸Šè¿°é¡¹ç›®ç»“æ„ï¼Œå°†æå–çš„`dataset/`å’Œ`result/`æ–‡ä»¶å¤¹æ”¾åœ¨æ ¹ç›®å½•ä¸­
  
2. **éªŒè¯é¡¹ç›®ç»“æ„**ï¼š
   - ç¡®ä¿é¡¹ç›®ç›®å½•ä¸ä¸Šè¿°ç»“æ„åŒ¹é…ï¼ŒåŒ…æ‹¬`requirements.txt`æ–‡ä»¶

3. **å®‰è£…ä¾èµ–é¡¹**ï¼š
   - åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆå»ºè®®é¿å…å†²çªï¼‰ï¼š
     ```bash
     python -m venv env
     source env/bin/activate  # On Windows: env\Scripts\activate
     ```
   - å®‰è£…`requirements.txt`ä¸­åˆ—å‡ºçš„ä¾èµ–é¡¹ï¼š
     ```bash
     pip install -r requirements.txt
     ```

### è¿è¡Œå®éªŒï¼š

1. è¿›å…¥`src/`ç›®å½•ï¼š
   ```bash
   cd src
   ```

2. æ‰§è¡Œç›®æ ‡è„šæœ¬ï¼Œå¹¶æŒ‡å®šGPUè®¾å¤‡IDï¼ˆä¾‹å¦‚ï¼š`0`ã€`1`ï¼‰ï¼š
   ```bash
   bash <script_name>.sh device=<ID>
   ```
   ç¤ºä¾‹ï¼š
   ```bash
   bash default_exps.sh device=0
   ```

3. æŒ‰éœ€å¯¹å…¶ä»–è„šæœ¬é‡å¤ä¸Šè¿°æ“ä½œï¼ˆå¦‚`default_exps.sh`ï¼Œ`nlayer_exps.sh`ç­‰ï¼‰

#### ä½¿ç”¨`train.py`è„šæœ¬ï¼š

`train.py`ç”¨äºè®­ç»ƒå’Œè¯„ä¼°å‚…é‡Œå¶ç¥ç»ç®—å­æ¨¡å‹ï¼ˆ`FNO2d`ã€`FDON2d`ã€`FDON2d_II`ï¼‰ï¼Œæ”¯æŒçƒ­æ‰©æ•£ç­‰ä»»åŠ¡ã€‚

**æ ¸å¿ƒåŠŸèƒ½**
- **è®­ç»ƒ**ï¼šä½¿ç”¨L2æŸå¤±ã€Adamä¼˜åŒ–å™¨å’Œä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦ã€‚æ”¯æŒ`FNO2d`ï¼ˆè¾“å…¥ï¼šåˆå€¼æ¡ä»¶ï¼‰å’Œ`FDON2d`/`FDON2d_II`ï¼ˆè¾“å…¥ï¼šåˆè¾¹å€¼æ¡ä»¶ï¼‰ã€‚
- **æ¨ç†**ï¼šè®¡ç®—æµ‹è¯•é¢„æµ‹ã€ç›¸å¯¹L2æŸå¤±å’Œæ¨ç†æ—¶é—´ï¼ˆGPU/CPUï¼‰ã€‚
- **è¾“å‡º**ï¼šæ¨¡å‹æƒé‡ã€é¢„æµ‹ç»“æœã€æŸå¤±æ›²çº¿å’Œæ¨ç†æ—¶é—´ä¿å­˜è‡³`../result/<task>/<component>/`ã€‚

**å‘½ä»¤ç¤ºä¾‹**
```bash
python train.py --task heat-1T-zsquares --arch fno --num-train 600 --num-test 100 --batch-size 4 --device 0
```

### ç»“æœå¤„ç†ï¼š

å®Œæˆæ‰€æœ‰å®éªŒåï¼Œå¯¹ç»“æœè¿›è¡Œå¤„ç†ä»¥ç”Ÿæˆæœ€ç»ˆè¡¨æ ¼å’Œå›¾è¡¨ï¼š

1. è¿›å…¥`result/`ç›®å½•ï¼š
   ```bash
   cd result
   ```

2. è¿è¡Œç»“æœå¤„ç†è„šæœ¬ï¼š
   ```bash
   python result_process.py
   ```

è¯¥è„šæœ¬ä¼šæ±‡æ€»å®éªŒè¾“å‡ºæ•°æ®ï¼Œå¹¶ç”Ÿæˆä¸è®ºæ–‡ä¸­è¡¨æ ¼å’Œå›¾è¡¨å¯¹åº”çš„ç»“æœã€‚

å„è„šæœ¬æ‰€å¯¹åº”çš„è®ºæ–‡ä¸­çš„ç‰¹å®šè¡¨æ ¼å’Œå›¾åƒç»“æœå¦‚ä¸‹è¡¨ï¼š

| è„šæœ¬                  | å¯¹åº”çš„ç»“æœ                                |
|-----------------------|-------------------------------------------|
| `default_exps.sh`     | Table II, Table III, Table IV, Fig. 7, Fig. 8 |
| `nlayer_exps.sh`      | Fig. 9                                   |
| `ntrain_exps.sh`      | Fig. 9                                   |
| `modes_exps.sh`       | Fig. 9                                   |
| `width_exps.sh`       | Fig. 9                                   |
| `superres_exps.sh`    | Table V                                  |
| `seq_exps.sh`         | Fig. 10, Table VI                        |

## æ•°å€¼å®éªŒï¼š

FNOã€Type-1å’ŒType-2 Fourier-DONå‡ä½¿ç”¨Adamä¼˜åŒ–å™¨ï¼Œåˆ©ç”¨å°æ‰¹é‡æ¢¯åº¦ä¸‹é™è¿›è¡Œä¼˜åŒ–ã€‚è®¾ç½®åˆå§‹å­¦ä¹ ç‡ä¸º0.001ï¼Œè®­ç»ƒæ­¥æ•°ä¸º100ï¼Œæ‰¹æ¬¡å¤§å°ä¸º4ã€‚é»˜è®¤æ¯ä¸ªä»»åŠ¡çš„è®­ç»ƒæ ·æœ¬ä¸º600ä¸ªï¼Œæµ‹è¯•æ ·æœ¬ä¸º100ä¸ªã€‚

### æ•°æ®é›†ï¼š

å‚è€ƒè§£ç”±FreeFem++ä¸­å®ç°çš„æœ‰é™å…ƒæ³•ç”Ÿæˆï¼Œå…·ä½“è®¾ç½®å¦‚ä¸‹ï¼šå¯¹äºå•æ¸©é—®é¢˜ï¼Œåœ¨ $\Omega$ ä¸Šå– $129\times129$ çš„å››è¾¹å½¢ç½‘æ ¼ï¼Œæ—¶é—´ç¦»æ•£é‡‡ç”¨éšå¼å‘åæ¬§æ‹‰ã€‚è®¾ç½®æ—¶é—´æ­¥é•¿ $\Delta t=0.001$ ï¼Œä» $t=0$ è®¡ç®—è‡³ $t=1$ ï¼Œå…±1000æ­¥ã€‚æ¯ä¸€æ—¶é—´æ­¥éƒ½ä½¿ç”¨Picardè¿­ä»£æ±‚è§£éçº¿æ€§ç³»ç»Ÿï¼Œæ›´æ–°è§£ç›´è‡³ä¸¤æ¬¡è¿­ä»£é—´çš„æ®‹å·®é™ä½è‡³0.001æˆ–è¾¾åˆ°100æ¬¡è¿­ä»£ã€‚å¯¹äºåŒæ¸©é—®é¢˜ï¼Œåœ¨ $\Omega$ ä¸Šå– $257\times257$ çš„å››è¾¹å½¢ç½‘æ ¼ï¼Œæ—¶é—´ç¦»æ•£é‡‡ç”¨éšå¼å‘åæ¬§æ‹‰ã€‚è®¾ç½®æ—¶é—´æ­¥é•¿ $\Delta t=0.001$ ï¼Œä» $t=0$ è®¡ç®—è‡³ $t=1$ ï¼Œå…±1000æ­¥ã€‚æ¯ä¸€æ—¶é—´æ­¥éƒ½ä½¿ç”¨Picardè¿­ä»£æ±‚è§£éçº¿æ€§ç³»ç»Ÿï¼Œæ›´æ–°è§£ç›´è‡³ä¸¤æ¬¡è¿­ä»£é—´çš„æ®‹å·®é™ä½è‡³0.01æˆ–è¾¾åˆ°100æ¬¡è¿­ä»£ã€‚

ææ–™å‡½æ•°å’Œè¾¹å€¼æ¡ä»¶ä¸­çš„å‚æ•°è®¾ç½®å¦‚ä¸‹ï¼šä¸¤ä¸ªæ–¹å½¢åŒºåŸŸçš„å·¦ä¸‹è§’åœ¨(0,1)ä¸­éšæœºé‡‡æ ·ï¼Œå‚æ•° $t_1$ å’Œ $\beta_{\text{max}}$ åˆ†åˆ«åœ¨[0,1]å’Œ[9,11]ä¸­éšæœºé‡‡æ ·ã€‚è‹¥ $t_1,\beta_{\text{max}}$ ä¸ä½œä¸ºè¾“å…¥ï¼Œåˆ™è®¾ç½®ä¸ºé»˜è®¤å€¼ã€‚

### æ¨¡å‹ç²¾åº¦å®éªŒï¼š

å¯¹äºå›ºå®šè¾¹å€¼å‡½æ•°çš„ä»»åŠ¡ï¼Œæ ‡å‡†FNOæ–¹æ³•çš„ç›¸å¯¹ $L_2$ è¯¯å·®å¦‚ä¸‹ï¼š

<img src="./result/figs/table2.png" alt="table2" width="400" />

å¯¹äºéå›ºå®šè¾¹å€¼å‡½æ•°çš„ä»»åŠ¡ï¼Œä¸¤ç§Fourier-DONæ–¹æ³•çš„ç›¸å¯¹ $L_2$ è¯¯å·®å¦‚ä¸‹ï¼š

<img src="./result/figs/table3.png" alt="table3" width="400" />

å…¨éƒ¨ç®—å­å­¦ä¹ ä»»åŠ¡çš„è®¡ç®—æ•ˆç‡å¦‚ä¸‹ï¼š

<img src="./result/figs/table4.png" alt="table4" width="700" />

é»˜è®¤è®¾ç½®ä¸‹å…¨éƒ¨ç®—å­å­¦ä¹ ä»»åŠ¡çš„è®­ç»ƒåŠ¨æ€å¦‚ä¸‹ï¼š

<img src="./result/figs/training_dynamics.jpg" alt="training_dynamics" width="700" />

ä»¥ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ ä¸ºä¾‹ï¼Œå‚è€ƒè§£ã€ä¸¤ç±»Fourier-DONä»¥åŠç»å¯¹è¯¯å·®çš„å¯è§†åŒ–å¦‚ä¸‹ï¼š

<img src="./result/figs/ablation_study.jpg" alt="ablation_study" width="700" />

### æ¶ˆèå®éªŒï¼š

ä»¥ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ ä¸ºä¾‹ï¼Œä¸åŒè®­ç»ƒæ ·æœ¬æ•°é‡ã€Fourierå±‚æ•°ã€Fourierå±‚é€šé“æ•°ä»¥åŠFourieræ¨¡æ•°å¯¹ç²¾åº¦çš„å½±å“å¦‚ä¸‹ï¼š

<img src="./result/figs/heat_2T_preds.jpg" alt="heat_2T_preds" width="600" />

### æ³›åŒ–èƒ½åŠ›å®éªŒï¼š

#### è¶…åˆ†è¾¨ç‡æ³›åŒ–ï¼š

è€ƒè™‘ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ ï¼Œä¸åŒè®­ç»ƒæ•°æ®åˆ†è¾¨ç‡å¯¹ç²¾åº¦çš„å½±å“å¦‚ä¸‹ï¼š

<img src="./result/figs/table5.png" alt="table5" width="400" />

#### æ—¶é—´æ³›åŒ–ï¼š

è€ƒè™‘ä»»åŠ¡ $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ ï¼Œä¸åŒæ—¶åˆ» $\tau$ ä¸‹ä¸¤ç±»Fourier-DONçš„ $\ell_2$ ç›¸å¯¹è¯¯å·®å¦‚ä¸‹ï¼š

<img src="./result/figs/table6.png" alt="table6" width="700" />

ä¸åŒæ—¶åˆ» $\tau$ ä¸‹å‚è€ƒè§£ã€ä¸¤ç±»Fourier-DONç»“æœä»¥åŠç»å¯¹è¯¯å·®å¯è§†åŒ–å¦‚ä¸‹ï¼š

<img src="./result/figs/heat_1T_seq_preds.jpg" alt="heat_1T_seq_preds" width="700" />

## æ•…éšœæ’é™¤ï¼š

- **GPUé”™è¯¯**ï¼šéªŒè¯GPUè®¾å¤‡IDï¼Œå¹¶ç¡®ä¿CUDAé©±åŠ¨ç¨‹åºä¸`requirements.txt`ä¸­çš„`torch`ç‰ˆæœ¬å…¼å®¹
- **ä¾èµ–ç¼ºå¤±**ï¼šè‹¥å‡ºç°é”™è¯¯ï¼Œè¯·ç¡®ä¿å·²å®‰è£…`requirements.txt`ä¸­åˆ—å‡ºçš„æ‰€æœ‰ä¾èµ–åŒ…ï¼Œå¹¶å‚è€ƒè®ºæ–‡æ£€æŸ¥é¢å¤–è¦æ±‚
- **ç»“æœä¸å®Œæ•´**ï¼šåœ¨å¤„ç†ç»“æœå‰ï¼Œç¡®ä¿æ‰€æœ‰å®éªŒå‡å·²æˆåŠŸè¿è¡Œã€‚
- **æ–‡ä»¶ç»“æ„é—®é¢˜**ï¼šç¡®è®¤`dataset/`ã€`result/`å’Œ`requirements.txt`æ–‡ä»¶è·¯å¾„æ­£ç¡®
- **ä»»åŠ¡é”™è¯¯**: ä»…ä½¿ç”¨`train.py`ä¸­åˆ—å‡ºçš„æ”¯æŒä»»åŠ¡ï¼ˆå¦‚`heat-1T-zsquares`ï¼‰

## è¡¥å……è¯´æ˜ï¼š

- `result_process.py`è„šæœ¬é»˜è®¤æ‰€æœ‰å®éªŒå‡å·²æˆåŠŸå®Œæˆ
- å®éªŒè¯¦ç»†è¯´æ˜åŠé¢„æœŸè¾“å‡ºè¯·å‚è€ƒè®ºæ–‡
- è¿›è¡Œå¤§è§„æ¨¡å®éªŒæ—¶ï¼Œè¯·ç›‘æ§ç³»ç»Ÿèµ„æºä»¥é¿å…å´©æºƒ

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Operator Learning for Nonlinear Diffusion Problems

## Operator Learning Methods:  

Fourier Neural Operator (FNO) and Deep Operator Network (DON) are representative approaches for learning differential operators, offering novel paradigms to address the challenge of cross-condition generalization in complex physical systems. FNO employs spectral-domain global convolutional kernels to capture long-range dependencies in multi-scale field evolution via Fourier transforms, while DON achieves efficient mapping in high-dimensional function spaces through implicit basis function decomposition and coefficient prediction. Existing operator learning methods have demonstrated advantages in linear and weakly nonlinear scenarios but still face challenges in multi-scale, strongly nonlinear problems.  

This project introduces two Fourier-DON variant architectures that combine FNO and DON to learn the mapping from equation conditions to solutions of the radiative diffusion equation at specific time points: The first variant uses FNO to generate basis functions and employs a fully connected network for coefficient processing, while the second adopts element-wise feature combination followed by an FNO decoder. Compared to traditional numerical methods (e.g., finite element methods), Fourier-DON is faster, more accurate, and more generalizable, enabling efficient simulation in complex physical systems.

## Nonlinear Radiation Diffusion Problem:

The nonlinear radiation diffusion problem represents a classic example of multiscale strongly coupled transport equations. At its core, it describes the nonlinear energy exchange process between radiation energy and material energy mediated by photon transport. The governing equations for this process can be expressed as follows.

### Single-Temperature Problem:

$$
\begin{aligned}
   & \frac{\partial E}{\partial t}-\nabla\cdot(D_L\nabla E) = 0, \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = \beta(x,y,t), \quad(x,y,t)\in\lbrace x=0\rbrace\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = 0, \quad(x,y,t)\in\partial\Omega\setminus\lbrace x=0\rbrace\times[0,1] \\
   & E|_{t=0} = g(x,y,0)
\end{aligned}
$$

where $\Omega = [0,1]\times[0,1]$ , while the radiation diffusion coefficient $D_L$ adopts the flux-limited form, expressed as $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}$ .

### Two-Temperature Problem:

$$
\begin{aligned}
   & \frac{\partial E}{\partial t} - \nabla \cdot (D_L \nabla E) = \sigma_{\alpha}(T^4 - E), \quad(x,y,t)\in\Omega\times[0,1] \\
   & \frac{\partial T}{\partial t} - \nabla \cdot (K_L \nabla T) = \sigma_{\alpha}(E - T^4), \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E + D_L \nabla E \cdot n = \beta(x,y,t), \quad (x,y,t) \in \lbrace x=0 \rbrace \times [0,1] \\
   & 0.5E + D_L \nabla E \cdot n = 0, \quad (x,y,t) \in \partial\Omega \setminus \lbrace x=0 \rbrace \times [0,1] \\
   & K_L \nabla T \cdot n = 0, \quad (x,y,t) \in \partial\Omega \times [0,1] \\
   & E\vert_{t=0} = T^4\vert_{t=0} = g(x,y,0)
\end{aligned}
$$

where $\Omega = [0,1]\times[0,1]$ , while the radiation diffusion coefficient $D_L, K_L$ also adopts the flux-limited form, expressed as $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}, K_L = \frac{T^4}{T^{3/2}z+T^{5/2}|\nabla T|}$ .

For the single-temperature and two-temperature problems mentioned above, the material function $z$ adopts a double-square configuration, where $z=9$ within two 0.25Ã—0.25 square regions in $\Omega$ , and $z=1$ elsewhere.

The initial condition is set as a constant value: $g(x,y,t) = 0.01$ . The boundary condition follows a linear profile: when $t<t_1$ , $\beta(x,y,t)=\frac{\beta_{\text{max}}}{t_1} t$ ; when $t\leq t_1$ , $\beta(x,y,t)=\beta_{\text{max}}$ .

### Operator Learning Tasks:

The six operator learning tasks that need to be studied in this project are as follows:

|                    | Tasks                          |
|--------------------|--------------------------------|
| single-temperature | $z \rightarrow E$              |
|                    | $z \times t_1 \rightarrow E$   |
|                    | $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ |
| two-temperature    | $z \rightarrow E, T$           |
|                    | $z \times t_1 \rightarrow E, T$ |
|                    | $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ |

## Design of Fourier-DON Algorithm:

The goal of this project is to develop a neural network surrogate model for handling multi-input operators $ğ’³_1\times ğ’³_2\times ... \times ğ’³_n\rightarrow ğ’´$ , where $ğ’³_1\times ğ’³_2\times ... \times ğ’³_n$ represents $n$ distinct input function spaces, and ğ’´ denotes the output function space. To achieve this, we modify the original DON architecture such that its branch and trunk networks can separately process discrete material functions (denoted as $Z$) and discrete boundary value functions (denoted as $\xi$). Two variants are developed: Type-1 Fourier-DON and Type-2 Fourier-DON.

The single-temperature task is used below to describe both variants. For the dual-temperature task, two Fourier-DON networks are employed to learn the target functions $ğ„,ğ“âˆˆâ„^{m\times m}$ , where $m$ represents the spatial dimension.

### Type-1 Fourier-DON

The architecture of Type-1 Fourier-DON is illustrated in the figure below, where the branch network is denoted as $B_\theta$ and the trunk network as $T_\theta$ .

<img src="./result/figs/fno-deeponet-type1.jpg" alt="type1-model" width="300" />

The material function ğ™ is first scaled to the range (0,1) and concatenated with the corresponding 2D grid coordinates $X,Yâˆˆâ„^{m\times m}$ , forming $[z,X,Y]âˆˆâ„^{m\times m\times 3}$ as the input to the branch network. The boundary condition parameters $t_1âˆˆâ„$ and $\beta_{\text{max}}âˆˆâ„$ are also scaled to (0,1) and concatenated into  $[t_1,\beta_{\text{max}}]âˆˆâ„^2$ , serving as the input to the trunk network.

The branch network begins with a linear layer that maps $â„^{m\times m\times 3}$ to $â„^{m\times m\times 32}$ , followed by four Fourier layers, each containing 12 modes and 32 channels. The pointwise transformation block within each layer is implemented as a two-layer fully connected network (FCN) with 32 hidden units per layer. The trunk network is configured as a four-layer FCN, each with 32 hidden units. The GeLU activation function is applied to all layers of both networks except the final layer.

The outputs of the branch and trunk networks are:

$$
\begin{aligned}
   & ğ• = B_\theta (ğ™)âˆˆâ„^{m\times m\times c}, \\
   & ğ›š = T_\theta (\xi)âˆˆâ„^c,
\end{aligned}
$$

where $c$ is the number of channels. Here, ğ• can be viewed as a set of basis functions $[ğ•_1,...,ğ•_c]$ , and ğ›š as a set of coefficients $[ğ›š_1,...,ğ›š_c]$ . For tasks with fixed boundary conditions, the trunk network can be omitted.

The discretized target function $ğ„âˆˆâ„^{m\times m}$ is approximated as:

$$
\begin{equation}
   ğ„Ìƒ = \sum_i ğ›š_i ğ•_i.
\end{equation}
$$

The loss function is defined as the relative $\ell_2$ -norm error:

$$
\begin{equation}
   L = \frac{1}{N} \sum_{k=1}^N \frac{â€–ğ„^{(k)}-ğ„Ìƒ^{(k)}â€–â‚‚}{â€–ğ„^{(k)}â€–â‚‚},
\end{equation}
$$

where $N$ denotes the number of samples, $ğ„^{(k)}$ is the $k$ -th FEM reference solution, and $ğ„Ìƒ^{(k)}$ is the corresponding neural network prediction.

Taking the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ as an example, the detailed training process of Type-1 Fourier-DON is illustrated in the figure below:

<img src="./result/figs/fno-deeponet-type1-train.jpg" alt="type1-train" width="700" />

### Type-2 Fourier-DON

The architecture of Type-2 Fourier-DON is illustrated in the figure below, with the decoder denoted as $\Phi_\theta$ .

<img src="./result/figs/fno-deeponet-type2.jpg" alt="type2-model" width="400" />

The input layers for both the branch network and trunk network remain identical to those in Type-1.

Both the branch and trunk networks are implemented via a linear layer that maps $â„^{m\times m\times 3}$ to $â„^{m\times m\times 32}$ , followed by element-wise multiplication. The resulting output $ğ•âˆˆâ„^{m\times m\times 32}$ is fed into an FNO decoder, which consists of four Fourier layers (each identical to those in Type-1) and a two-layer FCN with 32 hidden units.

The discretized target function $ğ„âˆˆâ„^{m\times m}$ is approximated as:

$$
\begin{aligned}
   & ğ = B_\theta (ğ™)âˆˆâ„^{m\times m\times c}, \\
   & ğ— = T_\theta (\xi)âˆˆâ„^c, \\
   & ğ•_{i,j} = ğ_{i,j}âŠ™ğ—, \\
   & ğ„Ìƒ = \Phi_\theta (ğ•^{(0)})
\end{aligned}
$$

where $i,jâˆˆ[0,m-1]$ denote spatial indices of ğ and ğ•, and âŠ™ represents element-wise multiplication. For tasks with fixed boundary conditions $\beta(x,y,t)$ , the trunk network can be omitted.

The loss function is defined identically to that in Type-1.

Taking the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ as an example, the detailed training process of Type-2 Fourier-DON is illustrated in the figure below:

<img src="./result/figs/fno-deeponet-type2-train.jpg" alt="type2-train" width="700" />

## Code Introduction:

For single-temperature problems, a 129Ã—129 grid is used with a time step of 0.001. The Picard iteration continues until reaching a convergence threshold of 0.001 or completing 100 iterations, with FEM solutions serving as reference results. For two-temperature problems, a 257Ã—257 grid is employed with a time step of 0.001, iterating until convergence to 0.01 or 100 iterations, again using FEM solutions as references.

The input parameters include randomly sampled $z,t_1,\beta_{\text{max}}$ . The lower-left coordinates of parameter $z$ 's two square regions are sampled uniformly from (0,1), $t_1$ is sampled from [0,1], and $\beta_{\text{max}}$ is sampled from [9,11] to construct the source function $\beta(x,y,t)$ . For tasks using only $z$ as input, $t_1=0.5,\beta_{\text{max}}=10$ are fixed. For tasks with $z,t_1$ as inputs, $\beta_{\text{max}}=10$ is fixed.

Both operator variants employ the Adam optimizer with mini-batch gradient descent. A cosine annealing scheduler is used with an initial learning rate of 0.001, trained for 100 epochs with a batch size of 4. The default configuration uses 600 training samples and 100 test samples.

This repository contains scripts to reproduce the results from the paper on operator learning for solving nonlinear diffusion problems. Follow the instructions below to set up the project, run experiments, and process results.

## Project Structure

```
operator_learning-nonlinear_diffusion/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ nd/
â”‚   â””â”€â”€ nd_seq/
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ exps/
â”‚   â”œâ”€â”€ seq_exps/
â”‚   â”œâ”€â”€ figs/
â”‚   â””â”€â”€ result_process.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ nets.py
â”‚   â”œâ”€â”€ utils.sh
â”‚   â”œâ”€â”€ default_exps.sh
â”‚   â”œâ”€â”€ nlayer_exps.sh
â”‚   â”œâ”€â”€ ntrain_exps.sh
â”‚   â”œâ”€â”€ modes_exps.sh
â”‚   â”œâ”€â”€ width_exps.sh
â”‚   â”œâ”€â”€ superres_exps.sh
â”‚   â””â”€â”€ seq_exps.sh
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### Parameter Specification:

|Parameter      |Description      |Default      |
|:--------:|:--------:|:--------:|
|data-root    |Path to dataset directory ("../dataset/nd/" or "../dataset/nd_seq/")        |../dataset/nd/       |
|task         |Task name (e.g., "heat-1T-zsquares", "heat-2T-zsquares-t1-bmax")    |heat-1T-zsquares     |
|num-train   |Number of training samples                      |600          |
|num-test    |Number of test samples                      |100          |
|batch-size  |Batch size for training                      |4            |
|seed        |Random seed for reproducibility            |0           |
|lr          |Initial learning rate                        |1e-3         |
|epochs      |Number of training epochs                        |100          |
|modes       |Number of Fourier modes in x and y directions               |12           |
|width       |Number of channels in the network                        |32           |
|grid-size   |Spatial grid resolution                     |129          |
|output-dir  |Directory to save training results                   |../result/   |
|num-branch  |Number of branch layers (Fourier layers)              |4            |
|num-trunk   |Number of trunk layers (linear layers for FDON2d)         |2            |
|device      |GPU device ID                         |0            |
|ratio       |Spatial sampling ratio (1, 2, or 4)              |1            |
|arch        |Model architecture (fno, fdon1, fdon2)|fno          |

### Prerequisites:

- A system with a compatible GPU (ensure valid GPU device IDs are available).
- Python (version compatible with dependencies, e.g., Python 3.8+) and Bash installed.
- Required Python dependencies listed in `requirements.txt` (e.g., `torch`, `numpy`, `scipy`, `matplotlib`).
- Ensure Pytorch installed with GPU support.
- Access to the dataset and results (download link below).

### Setup:

1. **Download Dataset and Results**:
   - Access the dataset and results at: [https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde](https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde).
   - Unzip `dataset.zip` and `result.zip`.
   - Place the extracted `dataset/` and `result/` folders in the root directory as shown in the project structure.

2. **Verify Project Structure**:
   - Ensure the project directory matches the structure above, including the `requirements.txt` file.

3. **Install Dependencies**:
   - Create a virtual environment (recommended to avoid conflicts):
     ```bash
     python -m venv env
     source env/bin/activate  # On Windows: env\Scripts\activate
     ```
   - Install dependencies from `requirements.txt`:
     ```bash
     pip install -r requirements.txt
     ```

### Running Experiments:

1. Navigate to the `src/` directory:
   ```bash
   cd src
   ```

2. Execute the desired script, specifying the GPU device ID (e.g., `0`, `1`):
   ```bash
   bash <script_name>.sh device=<ID>
   ```
   Example:
   ```bash
   bash default_exps.sh device=0
   ```

3. Repeat for each script as needed (`default_exps.sh`, `nlayer_exps.sh`, etc.).

#### Using the `train.py` script:

The `train.py` script trains and performs inference with Fourier Neural Operator models (`FNO2d`, `FDON2d`, `FDON2d_II`) for tasks like heat diffusion. 

**Key Features**:
- **Training**: Trains models using L2 loss, Adam optimizer, and cosine annealing learning rate scheduling. Supports `FNO2d` (input: initial conditions) and `FDON2d`/`FDON2d_II` (inputs: initial conditions and boundary conditions).
- **Inference**: Computes test predictions, relative L2 loss, and inference times (GPU/CPU).
- **Output**: Saves model weights, predictions, loss dynamics, and inference times to `../result/<task>/<component>/`.

**Command Example**:
```bash
python train.py --task heat-1T-zsquares --arch fno --num-train 600 --num-test 100 --batch-size 4 --device 0
```

### Processing Results:

After completing all experiments, process the results to generate the final tables and figures:

1. Navigate to the `result/` directory:
   ```bash
   cd result
   ```

2. Run the result processing script:
   ```bash
   python result_process.py
   ```

This script aggregates experiment outputs and produces the results corresponding to the paperâ€™s tables and figures.

The following scripts generate results for specific tables and figures in the paper:

| Script                | Generates Results For                     |
|-----------------------|-------------------------------------------|
| `default_exps.sh`     | Table II, Table III, Table IV, Fig. 7, Fig. 8 |
| `nlayer_exps.sh`      | Fig. 9                                   |
| `ntrain_exps.sh`      | Fig. 9                                   |
| `modes_exps.sh`       | Fig. 9                                   |
| `width_exps.sh`       | Fig. 9                                   |
| `superres_exps.sh`    | Table V                                  |
| `seq_exps.sh`         | Fig. 10, Table VI                        |

## Numerical Experiments:

### Accuracy and Efficiency Experiments:

For tasks with fixed boundary value functions, the relative $\ell_2$ -norm errors are as follows:

<img src="./result/figs/table2.png" alt="table2" width="400" />

For tasks with non-fixed boundary value functions, the relative $\ell_2$ -norm errors are as follows:

<img src="./result/figs/table3.png" alt="table3" width="400" />

The computational efficiency for all operator learning tasks is as follows:

<img src="./result/figs/table4.png" alt="table4" width="700" />

The training dynamics of all operator learning tasks under default settings are as follows:

<img src="./result/figs/training_dynamics.jpg" alt="training_dynamics" width="700" />

Taking the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ as an example, visualizations of reference solutions, two types of Fourier-DON results, and absolute errors are as follows:

<img src="./result/figs/ablation_study.jpg" alt="ablation_study" width="700" />

### Ablation Experiments:

Taking the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ the impact of different training sample sizes, number of Fourier layers, Fourier layer channels, and Fourier modes on accuracy is as follows:

<img src="./result/figs/heat_2T_preds.jpg" alt="heat_2T_preds" width="600" />

### Generalization Capabilities Experiments:

#### Supperresolution performance:

Considering the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ the influence of different training data resolutions on accuracy is as follows:

<img src="./result/figs/table5.png" alt="table5" width="400" />

#### Temporal generalization:

Considering the task $z \times t_1 \times \beta_{\text{max}} \rightarrow E$ the relative $\ell_2$ -norm errors of two Fourier-DON types at different time steps $\tau$ are as follows:

<img src="./result/figs/table6.png" alt="table6" width="700" />

Visualizations of reference solutions, two Fourier-DON results, and absolute errors at different time steps $\tau$ are as follows:

<img src="./result/figs/heat_1T_seq_preds.jpg" alt="heat_1T_seq_preds" width="700" />

## Troubleshooting:

- **GPU Errors**: Verify the GPU device ID and ensure CUDA drivers are compatible with the `torch` version in `requirements.txt`.
- **Missing Dependencies**: If errors occur, ensure all packages in `requirements.txt` are installed. Check the paper for additional requirements.
- **Incomplete Results**: Ensure all experiments have run successfully before processing results.
- **File Structure Issues**: Confirm `dataset/`, `result/`, and `requirements.txt` are correctly placed.
- **Task Errors**: Use supported tasks (e.g., `heat-1T-zsquares`) as listed in `train.py`.

## Additional Notes:

- The `result_process.py` script assumes all experiments have completed successfully.
- Refer to the paper for detailed experiment descriptions and expected outputs.
- For large-scale experiments, monitor system resources to prevent crashes.
