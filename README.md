# éçº¿æ€§æ‰©æ•£é—®é¢˜çš„ç®—å­å­¦ä¹ 

## ç®—å­å­¦ä¹ æ–¹æ³•ï¼š

å‚…é‡Œå¶ç¥ç»ç®—å­ï¼ˆFNOï¼‰ä¸æ·±åº¦ç®—å­ç½‘ç»œï¼ˆDONï¼‰ä½œä¸ºå¾®åˆ†ç®—å­å­¦ä¹ çš„ä»£è¡¨æ€§æ–¹æ³•ï¼Œä¸ºè§£å†³å¤æ‚ç‰©ç†ç³»ç»Ÿçš„è·¨æ¡ä»¶æ³›åŒ–éš¾é¢˜æä¾›äº†æ–°èŒƒå¼ã€‚FNOåŸºäºè°±åŸŸå…¨å±€å·ç§¯æ ¸ï¼Œé€šè¿‡å‚…é‡Œå¶å˜æ¢æ•æ‰å¤šå°ºåº¦åœºæ¼”åŒ–çš„é•¿ç¨‹ä¾èµ–æ€§ï¼›DONé€šè¿‡éšå¼åŸºå‡½æ•°åˆ†è§£ä¸ç³»æ•°é¢„æµ‹å®ç°é«˜ç»´å‡½æ•°ç©ºé—´çš„é«˜æ•ˆæ˜ å°„ã€‚ç°æœ‰ç®—å­å­¦ä¹ æ–¹æ³•åœ¨çº¿æ€§åŠå¼±éçº¿æ€§åœºæ™¯ä¸­å·²å±•ç°ä¼˜åŠ¿ï¼Œä½†åœ¨å¤šå°ºåº¦ã€å¼ºéçº¿æ€§é—®é¢˜ä¸­ä»é¢ä¸´æŒ‘æˆ˜ã€‚

æœ¬é¡¹ç›®æå‡ºä¸¤ç§Fourier-DONæ¶æ„ï¼Œå°†FNOä¸DONä¸¤è€…ç»“åˆï¼Œä»¥å­¦ä¹ ä»æ–¹ç¨‹æ¡ä»¶åˆ°ç‰¹å®šæ—¶é—´ç‚¹è¾å°„æ‰©æ•£æ–¹ç¨‹è§£çš„æ˜ å°„ï¼šç¬¬ä¸€ç±»ä½¿ç”¨FNOç”ŸæˆåŸºå‡½æ•°ï¼Œå¹¶é‡‡ç”¨å…¨è¿æ¥ç½‘ç»œå¤„ç†ç³»æ•°ï¼›ç¬¬äºŒç±»åˆ™é‡‡ç”¨é€å…ƒç´ ç‰¹å¾ç»„åˆåæ¥FNOè§£ç å™¨ã€‚ç›¸æ¯”ä¼ ç»Ÿæ•°å€¼æ–¹æ³•ï¼ˆå¦‚æœ‰é™å…ƒæ³•ï¼‰ï¼ŒFourier-DONè¦æ›´åŠ å¿«é€Ÿã€å‡†ç¡®ä¸”ä¾¿äºæ¨å¹¿ï¼Œèƒ½å¤Ÿå®ç°å¤æ‚ç‰©ç†ç³»ç»Ÿä¸­çš„é«˜æ•ˆæ¨¡æ‹Ÿã€‚

## éçº¿æ€§è¾å°„æ‰©æ•£é—®é¢˜ï¼š

éçº¿æ€§è¾å°„æ‰©æ•£é—®é¢˜æ˜¯ä¸€ç±»å…¸å‹çš„å¤šå°ºåº¦å¼ºè€¦åˆè¾“è¿æ–¹ç¨‹ï¼Œå…¶æ ¸å¿ƒåœ¨äºæè¿°è¾å°„èƒ½é‡ä¸ç‰©è´¨èƒ½é‡é€šè¿‡å…‰å­è¾“è¿äº§ç”Ÿçš„éçº¿æ€§èƒ½é‡äº¤æ¢è¿‡ç¨‹ã€‚è¯¥è¿‡ç¨‹çš„æ§åˆ¶æ–¹ç¨‹å¯è¡¨è¿°ä¸ºï¼š

### å•æ¸©é—®é¢˜ï¼š

$$
\begin{aligned}
   & \frac{\partial E}{\partial t}-\nabla\cdot(D_L\nabla E) = 0, \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = \beta(x,y,t), \quad(x,y,t)\in\lbrace x=0\rbrace\times[0,1] \\
   & 0.5E+D_L\nabla E\cdot n = 0, \quad(x,y,t)\in\partial\Omega\setminus\lbrace x=0\rbrace\times[0,1] \\
   & E|_{t=0} = g(x,y,0)
\end{aligned}
$$

å…¶ä¸­ $\Omega = [0,1]\times[0,1]$ ï¼›è¾å°„æ‰©æ•£ç³»æ•° $D_L$ é€‰ç”¨é™æµå½¢å¼ï¼Œå³ $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}$ ã€‚

### åŒæ¸©é—®é¢˜ï¼š

$$
\begin{aligned}
   & \frac{\partial E}{\partial t} - \nabla \cdot (D_L \nabla E) = \sigma_{\alpha}(T^4 - E), \quad(x,y,t)\in\Omega\times[0,1] \\
   & \frac{\partial T}{\partial t} - \nabla \cdot (K_L \nabla T) = \sigma_{\alpha}(E - T^4), \quad(x,y,t)\in\Omega\times[0,1] \\
   & 0.5E + D_L \nabla E \cdot n = \beta(x,y,t), \quad (x,y,t) \in \lbrace x=0 \rbrace \times [0,1] \\
   & 0.5E + D_L \nabla E \cdot n = 0, \quad (x,y,t) \in \partial\Omega \setminus \lbrace x=0 \rbrace \times [0,1] \\
   & K_L \nabla T \cdot n = 0, \quad (x,y,t) \in \partial\Omega \times [0,1] \\
   & E\vert_{t=0} = g(x,y,0) \\
   & T^4\vert_{t=0} = g(x,y,0)
\end{aligned}
$$

å…¶ä¸­ $\Omega = [0,1]\times[0,1]$ ï¼›è¾å°„æ‰©æ•£ç³»æ•° $D_L, K_L$ åŒæ ·é€‰ç”¨é™æµå½¢å¼ï¼Œå³ $D_L = \frac{1}{3\sigma_{\alpha}+\frac{|\nabla E|}{E}}, \sigma_{\alpha} = \frac{z^3}{E^{3/4}}, K_L = \frac{T^4}{T^{3/2}z+T^{5/2}|\nabla T|}$ ã€‚

å¯¹äºä¸Šè¿°å•æ¸©ã€åŒæ¸©é—®é¢˜ï¼Œç”µç¦»åº¦å‡½æ•° $Z$ é‡‡ç”¨åŒæ–¹å½¢ï¼Œå³å½“ $\frac{3}{16}<x<\frac{7}{16}, \frac{9}{16}<y<\frac{13}{16}$ æˆ– $\frac{9}{16}<x<\frac{13}{16}, \frac{3}{16}<y<\frac{7}{16}$ æ—¶ï¼Œ $Z=10$ ï¼›å…¶ä»–æ—¶å€™ $Z=1$ ã€‚

åˆè¾¹å€¼æ¡ä»¶é‡‡ç”¨å¸¸æ•°åˆå€¼+çº¿æ€§è¾¹å€¼ï¼Œå³ $\beta (x,y,t) = \max$ { $20t, 10$ }, $g(x,y,t) = 0.01$ ã€‚

### ç®—å­å­¦ä¹ é—®é¢˜ï¼š

æœ¬é¡¹ç›®éœ€è¦ç ”ç©¶çš„å…­ä¸ªç®—å­å­¦ä¹ é—®é¢˜å¦‚ä¸‹ï¼š

|                    | Tasks                          |
|--------------------|--------------------------------|
| single-temperature | â‘  $Z \rightarrow E$            |
|                    | â‘¡ $Z \times t_1 \rightarrow E$ |
|                    | â‘¢ $Z \times t_1 \times \beta_{\text{max}} \rightarrow E$ |
| single-temperature | â‘£ $Z \rightarrow E, T$         |
|                    | â‘¤ $Z \times t_1 \rightarrow E, T$ |
|                    | â‘¥ $Z \times t_1 \times \beta_{\text{max}} \rightarrow E, T$ |

## Fourier-DONç®—æ³•è®¾è®¡ï¼š

æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯æ‰¾ä¸€ä¸ªæ›¿ä»£æ¨¡å‹ï¼Œç”¨äºå¤„ç†å¤šè¾“å…¥ç®—å­ $ğ’¢:ğ’³_1\times ğ’³_2\times ... \times ğ’³_n\rightarrow ğ’´$ ï¼Œå…¶ä¸­ $ğ’³_1\times ğ’³_2\times ... \times ğ’³_n$ è¡¨ç¤º $n$ ä¸ªä¸åŒçš„è¾“å…¥å‡½æ•°ç©ºé—´ï¼Œğ’´æ˜¯è¾“å‡ºå‡½æ•°ç©ºé—´ã€‚ä»¥ä¸Šè¿°ç®—å­å­¦ä¹ é—®é¢˜â‘¡ä¸ºä¾‹ï¼Œå‡è®¾æœ‰ $N$ å¯¹å‚è€ƒæ•°å€¼è§£ $\{Z^{(k)},\beta^{(k)},E^{(k)}\}$ $_{k=1}^N$ ï¼Œåˆ™ $Z^{(k)}âˆˆğ’³_1, \beta^{(k)}âˆˆğ’³_2, E^{(k)}âˆˆğ’´$ ï¼Œç›®æ ‡æ˜¯è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ $ğ’¢_{\theta}$ ï¼Œå…¶ä¸­ $\theta$ è¡¨ç¤ºç¥ç»ç½‘ç»œçš„å¯å­¦ä¹ å‚æ•°ï¼Œé€šè¿‡æœ€å°åŒ–æŸå¤±å‡½æ•°ğ’æ¥è¿‘ä¼¼ğ’¢ï¼š

$$
\begin{equation}
   \min_{\theta}\frac{1}{N}\sum_{k=1}^N ğ’(ğ’¢_{\theta}(Z^{(k)},\beta^{(k)}),E^{(k)}).
\end{equation}
$$

è¯¥ç®—æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†åœ¨äºFourierå±‚ï¼Œå®ƒç»“åˆäº†æ ¸ç§¯åˆ†å˜æ¢å’Œé€ç‚¹å˜æ¢ï¼Œéšååº”ç”¨éçº¿æ€§æ¿€æ´»å‡½æ•° $\sigma$ ï¼š

$$
\begin{equation}
   ğ•^{(l+1)} = \sigma(â„±^{-1}(ğ‘\cdot â„±(V^{(l)})) + ğ’²(ğ•^{(l)})).
\end{equation}
$$









# Operator Learning for Nonlinear Diffusion Problems

This repository contains scripts to reproduce the results from the paper on operator learning for solving nonlinear diffusion problems. Follow the instructions below to set up the project, run experiments, and process results.

## Project Structure

```
operator_learning-nonlinear_diffusion/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ nd/
â”‚   â””â”€â”€ nd_seq/
â”œâ”€â”€ result/
â”‚   â”œâ”€â”€ exps/
â”‚   â”œâ”€â”€ seq_exps/
â”‚   â”œâ”€â”€ figs/
â”‚   â””â”€â”€ result_process.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ nets.py
â”‚   â”œâ”€â”€ utils.sh
â”‚   â”œâ”€â”€ default_exps.sh
â”‚   â”œâ”€â”€ nlayer_exps.sh
â”‚   â”œâ”€â”€ ntrain_exps.sh
â”‚   â”œâ”€â”€ modes_exps.sh
â”‚   â”œâ”€â”€ width_exps.sh
â”‚   â”œâ”€â”€ superres_exps.sh
â”‚   â””â”€â”€ seq_exps.sh
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Prerequisites

- A system with a compatible GPU (ensure valid GPU device IDs are available).
- Python (version compatible with dependencies, e.g., Python 3.8+) and Bash installed.
- Required Python dependencies listed in `requirements.txt` (e.g., `torch`, `numpy`, `scipy`, `matplotlib`).
- Ensure Pytorch installed with GPU support.
- Access to the dataset and results (download link below).

## Setup

1. **Download Dataset and Results**:
   - Access the dataset and results at: [https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde](https://pan.baidu.com/s/1CEs6UBiWCt3dzjk-vs98og?pwd=nrde).
   - Unzip `dataset.zip` and `result.zip`.
   - Place the extracted `dataset/` and `result/` folders in the root directory as shown in the project structure.

2. **Verify Project Structure**:
   - Ensure the project directory matches the structure above, including the `requirements.txt` file.

3. **Install Dependencies**:
   - Create a virtual environment (recommended to avoid conflicts):
     ```bash
     python -m venv env
     source env/bin/activate  # On Windows: env\Scripts\activate
     ```
   - Install dependencies from `requirements.txt`:
     ```bash
     pip install -r requirements.txt
     ```

## Running Experiments

The following scripts generate results for specific tables and figures in the paper:

| Script                | Generates Results For                     |
|-----------------------|-------------------------------------------|
| `default_exps.sh`     | Table II, Table III, Table IV, Fig. 7, Fig. 8 |
| `nlayer_exps.sh`      | Fig. 9                                   |
| `ntrain_exps.sh`      | Fig. 9                                   |
| `modes_exps.sh`       | Fig. 9                                   |
| `width_exps.sh`       | Fig. 9                                   |
| `superres_exps.sh`    | Table V                                  |
| `seq_exps.sh`         | Fig. 10, Table VI                        |

### Steps to Run Experiments

1. Navigate to the `src/` directory:
   ```bash
   cd src
   ```

2. Execute the desired script, specifying the GPU device ID (e.g., `0`, `1`):
   ```bash
   bash <script_name>.sh device=<ID>
   ```
   Example:
   ```bash
   bash default_exps.sh device=0
   ```

3. Repeat for each script as needed (`default_exps.sh`, `nlayer_exps.sh`, etc.).

### Using the `train.py` Script

The `train.py` script trains and performs inference with Fourier Neural Operator models (`FNO2d`, `FDON2d`, `FDON2d_II`) for tasks like heat diffusion. 

**Key Features**:
- **Training**: Trains models using L2 loss, Adam optimizer, and cosine annealing learning rate scheduling. Supports `FNO2d` (input: initial conditions) and `FDON2d`/`FDON2d_II` (inputs: initial conditions and boundary conditions).
- **Inference**: Computes test predictions, relative L2 loss, and inference times (GPU/CPU).
- **Output**: Saves model weights, predictions, loss dynamics, and inference times to `../result/<task>/<component>/`.

**Command Example**:
```bash
python train.py --task heat-1T-zsquares --arch fno --num-train 600 --num-test 100 --batch-size 4 --device 0
```

**Key Arguments**:
- `--task`: Task name (e.g., `heat-1T-zsquares`, `heat-1T-zsquares-t1`).
- `--arch`: Model architecture (`fno`, `fdon1`, `fdon2`).
- `--num-train`/`--num-test`: Number of training/test samples.
- `--batch-size`: Batch size for training.
- `--device`: GPU device ID.
- `--epochs`: Number of training epochs (default: 100).
- `--lr`: Learning rate (default: 1e-3).
- `--modes`/`--width`: Fourier modes and network channels.
- Full list available via `python train.py --help`.

## Processing Results

After completing all experiments, process the results to generate the final tables and figures:

1. Navigate to the `result/` directory:
   ```bash
   cd result
   ```

2. Run the result processing script:
   ```bash
   python result_process.py
   ```

This script aggregates experiment outputs and produces the results corresponding to the paperâ€™s tables and figures.

## Troubleshooting

- **GPU Errors**: Verify the GPU device ID and ensure CUDA drivers are compatible with the `torch` version in `requirements.txt`.
- **Missing Dependencies**: If errors occur, ensure all packages in `requirements.txt` are installed. Check the paper for additional requirements.
- **Incomplete Results**: Ensure all experiments have run successfully before processing results.
- **File Structure Issues**: Confirm `dataset/`, `result/`, and `requirements.txt` are correctly placed.
- **Task Errors**: Use supported tasks (e.g., `heat-1T-zsquares`) as listed in `train.py`.

## Additional Notes

- The `result_process.py` script assumes all experiments have completed successfully.
- Refer to the paper for detailed experiment descriptions and expected outputs.
- For large-scale experiments, monitor system resources to prevent crashes.
